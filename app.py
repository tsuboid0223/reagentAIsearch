import streamlit as st
import requests
import google.generativeai as genai
import time
import re
import json
import pandas as pd
from urllib.parse import quote_plus
from io import StringIO
from datetime import datetime

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="åŒ–å­¦è©¦è–¬ ä¾¡æ ¼æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ ï¼ˆSERP APIç‰ˆï¼‰",
    page_icon="ğŸ§ª",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .product-card {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.5rem;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    .product-title {
        font-size: 1.3rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 0.5rem;
    }
    .product-info {
        font-size: 1rem;
        color: #495057;
        margin: 0.3rem 0;
    }
    .price-row {
        background-color: white;
        padding: 0.8rem;
        margin: 0.3rem 0;
        border-radius: 0.3rem;
        border-left: 4px solid #007bff;
    }
    .log-container {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.5rem;
        padding: 1rem;
        font-family: monospace;
        font-size: 0.85rem;
        max-height: 400px;
        overflow-y: auto;
        margin: 1rem 0;
    }
    .api-status {
        padding: 0.5rem 1rem;
        border-radius: 0.3rem;
        margin: 0.5rem 0;
        font-weight: bold;
    }
    .api-success {
        background-color: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
    }
    .api-warning {
        background-color: #fff3cd;
        color: #856404;
        border: 1px solid #ffeeba;
    }
</style>
""", unsafe_allow_html=True)

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚¯ãƒ©ã‚¹
class RealTimeLogger:
    def __init__(self, container):
        self.container = container
        self.logs = []
        
    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        self.logs.append(log_entry)
        
        with self.container:
            st.code("\n".join(self.logs[-30:]), language="log")

# Gemini APIè¨­å®š
def setup_gemini():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        return genai.GenerativeModel('gemini-2.0-flash')
    except Exception as e:
        st.error(f"âŒ Gemini APIè¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

# SERP APIè¨­å®šãƒã‚§ãƒƒã‚¯
def check_serp_api_config():
    """SERP APIèªè¨¼æƒ…å ±ã®ç¢ºèª"""
    try:
        # APIã‚­ãƒ¼èªè¨¼
        if "BRIGHTDATA_API_KEY" in st.secrets:
            return {
                'provider': 'brightdata',
                'auth_type': 'api_key',
                'api_key': st.secrets["BRIGHTDATA_API_KEY"],
                'available': True
            }
        # Username/Passwordèªè¨¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        elif "BRIGHTDATA_USERNAME" in st.secrets and "BRIGHTDATA_PASSWORD" in st.secrets:
            return {
                'provider': 'brightdata',
                'auth_type': 'basic',
                'username': st.secrets["BRIGHTDATA_USERNAME"],
                'password': st.secrets["BRIGHTDATA_PASSWORD"],
                'available': True
            }
    except:
        pass
    
    return {
        'provider': None,
        'available': False
    }

# å¯¾è±¡ECã‚µã‚¤ãƒˆã®å®šç¾©ï¼ˆ11ã‚µã‚¤ãƒˆï¼‰
TARGET_SITES = {
    "cosmobio": {"name": "ã‚³ã‚¹ãƒ¢ãƒã‚¤ã‚ª", "domain": "cosmobio.co.jp"},
    "funakoshi": {"name": "ãƒ•ãƒŠã‚³ã‚·", "domain": "funakoshi.co.jp"},
    "axel": {"name": "AXEL", "domain": "axel.as-1.co.jp"},
    "selleck": {"name": "Selleck", "domain": "selleck.co.jp"},
    "mce": {"name": "MCE", "domain": "medchemexpress.com"},
    "nakarai": {"name": "ãƒŠã‚«ãƒ©ã‚¤", "domain": "nacalai.co.jp"},
    "fujifilm": {"name": "å¯Œå£«ãƒ•ã‚¤ãƒ«ãƒ å’Œå…‰", "domain": "labchem-wako.fujifilm.com"},
    "kanto": {"name": "é–¢æ±åŒ–å­¦", "domain": "kanto.co.jp"},
    "tci": {"name": "TCI", "domain": "tcichemicals.com"},
    "merck": {"name": "Merck", "domain": "merck.com"},
    "wako": {"name": "å’Œå…‰ç´”è–¬", "domain": "hpc-j.co.jp"}
}

def search_with_brightdata_serp(query, serp_config, logger):
    """Bright Data SERP APIã§æ¤œç´¢ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    try:
        logger.log(f"  ğŸ”Œ Bright Data SERP APIä½¿ç”¨", "DEBUG")
        
        # èªè¨¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
        if serp_config.get('auth_type') == 'api_key':
            # APIã‚­ãƒ¼èªè¨¼
            logger.log(f"  ğŸ”‘ APIã‚­ãƒ¼èªè¨¼ã‚’ä½¿ç”¨", "DEBUG")
            
            # Bright Data SERP APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ­£ã—ã„å½¢å¼ï¼‰
            api_url = "https://api.brightdata.com/serp/google"
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã«APIã‚­ãƒ¼ã‚’è¨­å®š
            headers = {
                'Authorization': f'Bearer {serp_config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            params = {
                'q': query,
                'num': 10,
                'hl': 'ja',
                'gl': 'jp',
            }
            
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.get(
                api_url,
                headers=headers,
                params=params,
                timeout=30
            )
            
        else:
            # Basicèªè¨¼ï¼ˆUsername/Passwordï¼‰
            logger.log(f"  ğŸ” Basicèªè¨¼ã‚’ä½¿ç”¨", "DEBUG")
            
            api_url = "https://api.brightdata.com/serp/google"
            
            # èªè¨¼æƒ…å ±
            auth = (serp_config['username'], serp_config['password'])
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            params = {
                'q': query,
                'num': 10,
                'hl': 'ja',
                'gl': 'jp',
            }
            
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.get(
                api_url,
                auth=auth,
                params=params,
                timeout=30
            )
        
        if response.status_code == 200:
            logger.log(f"  âœ“ SERP APIå¿œç­”æˆåŠŸ", "DEBUG")
            return response.json()
        elif response.status_code == 401:
            logger.log(f"  âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„", "ERROR")
            return None
        elif response.status_code == 429:
            logger.log(f"  âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«åˆ°é”", "WARNING")
            return None
        else:
            logger.log(f"  âš ï¸ SERP API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}", "WARNING")
            logger.log(f"  ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text[:200]}", "DEBUG")
            return None
            
    except requests.exceptions.Timeout:
        logger.log(f"  â±ï¸ SERP APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "WARNING")
        return None
    except Exception as e:
        logger.log(f"  âŒ SERP APIã‚¨ãƒ©ãƒ¼: {str(e)}", "ERROR")
        return None

def extract_urls_from_serp_response(serp_data, domain, logger):
    """SERP APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰URLã‚’æŠ½å‡º"""
    urls = []
    
    try:
        # Bright Data SERP APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã«å¯¾å¿œ
        if 'organic_results' in serp_data:
            for result in serp_data['organic_results'][:10]:
                url = result.get('url', '')
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯
                if domain in url:
                    urls.append({
                        'url': url,
                        'title': result.get('title', ''),
                        'snippet': result.get('snippet', '')
                    })
        
        # ä»–ã®ä¸€èˆ¬çš„ãªSERP APIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        elif 'results' in serp_data:
            for result in serp_data['results'][:10]:
                url = result.get('link', '') or result.get('url', '')
                
                if domain in url:
                    urls.append({
                        'url': url,
                        'title': result.get('title', ''),
                        'snippet': result.get('snippet', '') or result.get('description', '')
                    })
        
        if urls:
            logger.log(f"  âœ“ SERP APIã‹ã‚‰{len(urls)}ä»¶ã®URLæŠ½å‡º", "INFO")
        else:
            logger.log(f"  â„¹ï¸ è©²å½“URLãªã—", "DEBUG")
        
        return urls
        
    except Exception as e:
        logger.log(f"  URLæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}", "WARNING")
        return []

def search_with_strategy(product_name, site_info, serp_config, logger):
    """SERP APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢æˆ¦ç•¥"""
    site_name = site_info["name"]
    domain = site_info["domain"]
    
    logger.log(f"ğŸ” {site_name}ã‚’æ¤œç´¢ä¸­", "INFO")
    
    # SERP APIåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    if not serp_config['available']:
        logger.log(f"  âŒ SERP APIæœªè¨­å®š", "ERROR")
        return []
    
    # æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå„ªå…ˆé †ï¼‰
    search_queries = [
        f"{product_name} ä¾¡æ ¼ site:{domain}",
        f"{product_name} site:{domain}",
        f"{product_name} ã‚«ã‚¿ãƒ­ã‚° site:{domain}",
    ]
    
    all_results = []
    
    for query_idx, query in enumerate(search_queries):
        logger.log(f"  æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³{query_idx+1}: {query[:60]}...", "DEBUG")
        
        # SERP APIã§æ¤œç´¢
        serp_data = search_with_brightdata_serp(query, serp_config, logger)
        
        if not serp_data:
            logger.log(f"  âš ï¸ SERP APIå¿œç­”ãªã—ã€æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸", "DEBUG")
            time.sleep(2)
            continue
        
        # URLã‚’æŠ½å‡º
        urls = extract_urls_from_serp_response(serp_data, domain, logger)
        
        if urls:
            for url_data in urls[:5]:
                all_results.append({
                    'url': url_data['url'],
                    'site': site_name,
                    'title': url_data['title'],
                    'snippet': url_data['snippet'],
                    'serp_data': serp_data
                })
            
            logger.log(f"  âœ… {len(urls)}ä»¶ã®URLå–å¾—æˆåŠŸ", "INFO")
            break
        
        # æ¬¡ã®ã‚¯ã‚¨ãƒªã¾ã§å¾…æ©Ÿ
        time.sleep(2)
    
    if all_results:
        logger.log(f"âœ… {site_name}: {len(all_results)}ä»¶ã®URLå–å¾—", "INFO")
    else:
        logger.log(f"âš ï¸ {site_name}: URLæœªç™ºè¦‹", "WARNING")
    
    return all_results

def extract_price_from_snippet(snippet, title, product_name, model, logger):
    """ã‚¹ãƒ‹ãƒšãƒƒãƒˆã¨ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ä¾¡æ ¼æƒ…å ±ã‚’æŠ½å‡º"""
    logger.log(f"  ğŸ’¡ ã‚¹ãƒ‹ãƒšãƒƒãƒˆåˆ†æä¸­", "DEBUG")
    
    try:
        prompt = f"""
ä»¥ä¸‹ã®Googleæ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã‚‰ã€åŒ–å­¦è©¦è–¬ã€Œ{product_name}ã€ã®ä¾¡æ ¼æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{title}

ã€ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€‘
{snippet}

ã€æŠ½å‡ºã™ã‚‹æƒ…å ±ã€‘
1. productName: è£½å“å
2. modelNumber: å‹ç•ªãƒ»ã‚«ã‚¿ãƒ­ã‚°ç•ªå·ï¼ˆã‚ã‚Œã°ï¼‰
3. manufacturer: ãƒ¡ãƒ¼ã‚«ãƒ¼åï¼ˆã‚ã‚Œã°ï¼‰
4. offers: ä¾¡æ ¼æƒ…å ±ã®ãƒªã‚¹ãƒˆ
   - size: å®¹é‡ãƒ»ã‚µã‚¤ã‚º
   - price: ä¾¡æ ¼ï¼ˆæ•°å€¤ã®ã¿ï¼‰
   - inStock: åœ¨åº«çŠ¶æ³ï¼ˆä¸æ˜ãªå ´åˆã¯trueï¼‰

ã€é‡è¦ã€‘
- ä¾¡æ ¼æƒ…å ±ï¼ˆÂ¥ã€å††ã€$ã€priceï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯å¿…ãšæŠ½å‡º
- å‹ç•ªã¨ä¾¡æ ¼ãŒã‚»ãƒƒãƒˆã§è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å¯¾å¿œä»˜ã‘ã¦æŠ½å‡º
- ä¾¡æ ¼æƒ…å ±ãŒãªã„å ´åˆã¯offersã‚’ç©ºé…åˆ—ã«

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã®ã¿ã€‚ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ä¸è¦ã€‚
"""
        
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        response_text = re.sub(r'^```json\s*', '', response_text)
        response_text = re.sub(r'^```\s*', '', response_text)
        response_text = re.sub(r'\s*```$', '', response_text)
        response_text = response_text.strip()
        
        price_info = json.loads(response_text)
        
        if price_info.get('offers'):
            logger.log(f"  âœ… ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã‚‰{len(price_info['offers'])}ä»¶ã®ä¾¡æ ¼æŠ½å‡º", "INFO")
            return price_info
        else:
            logger.log(f"  â„¹ï¸ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã«ä¾¡æ ¼æƒ…å ±ãªã—", "DEBUG")
            return None
            
    except Exception as e:
        logger.log(f"  ã‚¹ãƒ‹ãƒšãƒƒãƒˆè§£æã‚¨ãƒ©ãƒ¼: {str(e)}", "DEBUG")
        return None

def fetch_page_content(url, logger):
    """ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8',
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            logger.log(f"  âœ“ ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ", "DEBUG")
            return response.text
        else:
            logger.log(f"  âš ï¸ ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: HTTP {response.status_code}", "DEBUG")
            return None
    except Exception as e:
        logger.log(f"  ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}", "DEBUG")
        return None

def extract_product_info_from_page(html_content, product_name, model, logger):
    """ãƒšãƒ¼ã‚¸HTMLã‹ã‚‰è£½å“æƒ…å ±ã‚’æŠ½å‡º"""
    logger.log(f"  ğŸ¤– ãƒšãƒ¼ã‚¸å†…å®¹ã‚’AIåˆ†æä¸­", "DEBUG")
    
    try:
        html_content = html_content[:50000]
        
        prompt = f"""
ä»¥ä¸‹ã®HTMLã‹ã‚‰åŒ–å­¦è©¦è–¬ã€Œ{product_name}ã€ã®è£½å“æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºæƒ…å ±ã€‘
1. productName: è£½å“å
2. modelNumber: å‹ç•ª
3. manufacturer: ãƒ¡ãƒ¼ã‚«ãƒ¼å
4. offers: ä¾¡æ ¼æƒ…å ±
   - size, price, inStock

JSONå½¢å¼ã§å‡ºåŠ›ã€‚

HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„:
{html_content}
"""
        
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        response_text = re.sub(r'^```json\s*', '', response_text)
        response_text = re.sub(r'^```\s*', '', response_text)
        response_text = re.sub(r'\s*```$', '', response_text)
        response_text = response_text.strip()
        
        product_info = json.loads(response_text)
        
        if product_info.get('offers'):
            logger.log(f"  âœ… ãƒšãƒ¼ã‚¸ã‹ã‚‰{len(product_info['offers'])}ä»¶ã®ä¾¡æ ¼æŠ½å‡º", "INFO")
        else:
            logger.log(f"  â„¹ï¸ ãƒšãƒ¼ã‚¸ã«ä¾¡æ ¼æƒ…å ±ãªã—", "DEBUG")
        
        return product_info
        
    except Exception as e:
        logger.log(f"  ãƒšãƒ¼ã‚¸è§£æã‚¨ãƒ©ãƒ¼: {str(e)}", "DEBUG")
        return None

def merge_product_info(snippet_info, page_info):
    """æƒ…å ±ã‚’ãƒãƒ¼ã‚¸"""
    if not snippet_info and not page_info:
        return None
    
    if not snippet_info:
        return page_info
    
    if not page_info:
        return snippet_info
    
    # ä¾¡æ ¼æƒ…å ±ãŒå¤šã„æ–¹ã‚’ãƒ™ãƒ¼ã‚¹ã«
    if len(snippet_info.get('offers', [])) >= len(page_info.get('offers', [])):
        merged = snippet_info.copy()
        if not merged.get('productName'):
            merged['productName'] = page_info.get('productName')
        if not merged.get('modelNumber'):
            merged['modelNumber'] = page_info.get('modelNumber')
        if not merged.get('manufacturer'):
            merged['manufacturer'] = page_info.get('manufacturer')
    else:
        merged = page_info.copy()
        if not merged.get('productName'):
            merged['productName'] = snippet_info.get('productName')
        if not merged.get('modelNumber'):
            merged['modelNumber'] = snippet_info.get('modelNumber')
        if not merged.get('manufacturer'):
            merged['manufacturer'] = snippet_info.get('manufacturer')
    
    return merged

def display_product_card(product, idx):
    """è£½å“æƒ…å ±ã‚’è¡¨ç¤º"""
    st.markdown(f'<div class="product-card">', unsafe_allow_html=True)
    
    product_name = product.get('productName', 'è£½å“åä¸æ˜')
    site_name = product.get('source_site', 'ä¸æ˜')
    st.markdown(f'<div class="product-title">ğŸ“¦ {product_name}</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown(f'<div class="product-info"><strong>è²©å£²å…ƒ:</strong> {site_name}</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="product-info"><strong>å‹ç•ª:</strong> {product.get("modelNumber", "N/A")}</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="product-info"><strong>ãƒ¡ãƒ¼ã‚«ãƒ¼:</strong> {product.get("manufacturer", "N/A")}</div>', unsafe_allow_html=True)
    
    with col2:
        source_url = product.get('source_url', '#')
        st.markdown(f'<div class="product-info"><strong>URL:</strong> <a href="{source_url}" target="_blank">è£½å“ãƒšãƒ¼ã‚¸ã‚’é–‹ã</a></div>', unsafe_allow_html=True)
    
    if 'offers' in product and product['offers']:
        st.markdown("**ğŸ’° ä¾¡æ ¼æƒ…å ±:**")
        
        for offer in product['offers']:
            size = offer.get('size', 'N/A')
            price = offer.get('price', 0)
            price_str = f"Â¥{price:,}" if price else 'N/A'
            stock = offer.get('inStock', False)
            stock_icon = "âœ…" if stock else "âŒ"
            stock_text = "åœ¨åº«ã‚ã‚Š" if stock else "åœ¨åº«ãªã—"
            
            st.markdown(
                f'<div class="price-row">'
                f'<strong>{size}</strong>: {price_str} {stock_icon} {stock_text}'
                f'</div>',
                unsafe_allow_html=True
            )
    else:
        st.warning("âš ï¸ ä¾¡æ ¼æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    st.markdown('</div>', unsafe_allow_html=True)

def main():
    st.markdown('<h1 class="main-header">ğŸ§ª åŒ–å­¦è©¦è–¬ ä¾¡æ ¼æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ ï¼ˆSERP APIç‰ˆ v2ï¼‰</h1>', unsafe_allow_html=True)
    
    # SERP APIè¨­å®šãƒã‚§ãƒƒã‚¯
    serp_config = check_serp_api_config()
    
    # APIçŠ¶æ…‹è¡¨ç¤º
    if serp_config['available']:
        auth_type_display = "APIã‚­ãƒ¼" if serp_config.get('auth_type') == 'api_key' else "Basicèªè¨¼"
        st.markdown(
            f'<div class="api-status api-success">âœ… SERP APIæ¥ç¶š: {serp_config["provider"].upper()} ({auth_type_display})</div>',
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            '<div class="api-status api-warning">âš ï¸ SERP APIæœªè¨­å®š: secrets.tomlã«BRIGHTDATA_API_KEYã¾ãŸã¯BRIGHTDATA_USERNAME/PASSWORDã‚’è¿½åŠ ã—ã¦ãã ã•ã„</div>',
            unsafe_allow_html=True
        )
        st.info("""
        **SERP APIè¨­å®šæ–¹æ³•:**
        
        **ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: APIã‚­ãƒ¼èªè¨¼ï¼ˆæ¨å¥¨ï¼‰**
        ```toml
        BRIGHTDATA_API_KEY = "your_api_key"
        ```
        
        **ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: Username/Passwordèªè¨¼**
        ```toml
        BRIGHTDATA_USERNAME = "your_username"
        BRIGHTDATA_PASSWORD = "your_password"
        ```
        """)
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        product_name = st.text_input(
            "ğŸ” è£½å“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value="Quinpirole",
            placeholder="ä¾‹: Y-27632, DMSO, Trizol, Quinpirole"
        )
    
    with col2:
        max_sites = st.number_input(
            "æœ€å¤§æ¤œç´¢ã‚µã‚¤ãƒˆæ•°",
            min_value=1,
            max_value=11,
            value=5,
            step=1
        )
    
    st.markdown("---")
    
    # æ¤œç´¢ãƒœã‚¿ãƒ³ï¼ˆSERP APIæœªè¨­å®šæ™‚ã¯ç„¡åŠ¹åŒ–ï¼‰
    search_disabled = not serp_config['available']
    
    if st.button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True, disabled=search_disabled):
        if not product_name:
            st.warning("âš ï¸ è£½å“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        st.markdown("### ğŸ“ å‡¦ç†ãƒ­ã‚°")
        log_container = st.empty()
        logger = RealTimeLogger(log_container)
        
        start_time = time.time()
        logger.log(f"ğŸš€ å‡¦ç†é–‹å§‹: {product_name}", "INFO")
        auth_type_display = "APIã‚­ãƒ¼" if serp_config.get('auth_type') == 'api_key' else "Basicèªè¨¼"
        logger.log(f"ğŸ”Œ SERP API: {serp_config['provider'].upper()} ({auth_type_display})", "INFO")
        
        model = setup_gemini()
        if not model:
            st.error("âŒ Gemini APIã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        all_products = []
        sites_to_search = dict(list(TARGET_SITES.items())[:max_sites])
        
        for site_key, site_info in sites_to_search.items():
            search_results = search_with_strategy(product_name, site_info, serp_config, logger)
            
            if not search_results:
                time.sleep(2)
                continue
            
            result = search_results[0]
            
            # ã‚¹ãƒ‹ãƒšãƒƒãƒˆåˆ†æ
            snippet_info = extract_price_from_snippet(
                result['snippet'],
                result['title'],
                product_name,
                model,
                logger
            )
            
            # ãƒšãƒ¼ã‚¸åˆ†æ
            page_info = None
            html_content = fetch_page_content(result['url'], logger)
            if html_content:
                page_info = extract_product_info_from_page(html_content, product_name, model, logger)
            
            # ãƒãƒ¼ã‚¸
            merged_info = merge_product_info(snippet_info, page_info)
            
            if merged_info:
                merged_info['source_site'] = result['site']
                merged_info['source_url'] = result['url']
                all_products.append(merged_info)
                logger.log(f"âœ… {result['site']}: è£½å“æƒ…å ±å–å¾—æˆåŠŸ", "INFO")
            else:
                logger.log(f"âš ï¸ {result['site']}: è£½å“æƒ…å ±å–å¾—å¤±æ•—", "WARNING")
            
            time.sleep(3)
        
        elapsed_time = time.time() - start_time
        logger.log(f"ğŸ‰ å‡¦ç†å®Œäº†: {elapsed_time:.1f}ç§’", "INFO")
        
        st.markdown("---")
        st.markdown("## ğŸ“‹ æ¤œç´¢çµæœ")
        
        if not all_products:
            st.warning("âš ï¸ è£½å“æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        with_price = [p for p in all_products if p.get('offers')]
        without_price = [p for p in all_products if not p.get('offers')]
        
        st.success(f"âœ… {len(all_products)}ä»¶ã®è£½å“æƒ…å ±ã‚’å–å¾—ï¼ˆä¾¡æ ¼æƒ…å ±ã‚ã‚Š: {len(with_price)}ä»¶ã€å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’ï¼‰")
        
        for idx, product in enumerate(with_price + without_price):
            display_product_card(product, idx)
        
        # CSVå‡ºåŠ›
        st.markdown("---")
        st.markdown("## ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        export_data = []
        for product in all_products:
            base_info = {
                'è£½å“å': product.get('productName', 'N/A'),
                'å‹ç•ª': product.get('modelNumber', 'N/A'),
                'ãƒ¡ãƒ¼ã‚«ãƒ¼': product.get('manufacturer', 'N/A'),
                'è²©å£²å…ƒ': product.get('source_site', 'N/A'),
                'URL': product.get('source_url', 'N/A')
            }
            
            if 'offers' in product and product['offers']:
                for offer in product['offers']:
                    row = base_info.copy()
                    row['ã‚µã‚¤ã‚º'] = offer.get('size', 'N/A')
                    row['ä¾¡æ ¼'] = offer.get('price', 0)
                    row['åœ¨åº«'] = 'æœ‰' if offer.get('inStock') else 'ç„¡'
                    export_data.append(row)
            else:
                row = base_info.copy()
                row['ã‚µã‚¤ã‚º'] = 'N/A'
                row['ä¾¡æ ¼'] = 0
                row['åœ¨åº«'] = 'N/A'
                export_data.append(row)
        
        df = pd.DataFrame(export_data)
        
        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        csv_data = csv_buffer.getvalue()
        
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"chemical_prices_{product_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True
        )

if __name__ == "__main__":
    main()
